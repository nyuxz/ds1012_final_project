{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example for DRQA data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import tqdm\n",
    "def clean_spaces(text):\n",
    "    \"\"\"normalize spaces in a string.\"\"\"\n",
    "    text = re.sub(r'\\s', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', parser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WP']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_doc = nlp('who')\n",
    "[w.tag_ for w in c_doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import unicodedata\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize('NFD', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question = 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "q_doc = nlp(clean_spaces(question))\n",
    "c_doc = nlp(clean_spaces(context))\n",
    "question_tokens = [normalize_text(w.text) for w in q_doc]\n",
    "context_tokens = [normalize_text(w.text) for w in c_doc]\n",
    "question_tokens_lower = [w.lower() for w in question_tokens]\n",
    "context_tokens_lower = [w.lower() for w in context_tokens]\n",
    "context_token_span = [(w.idx, w.idx + len(w.text)) for w in c_doc] # the lenghth of each tokens\n",
    "context_tags = [w.tag_ for w in c_doc] # POS tagging\n",
    "context_ents = [w.ent_type_ for w in c_doc] # NER tagging\n",
    "\n",
    "question_lemma = {w.lemma_ if w.lemma_ != '-PRON-' else w.text.lower() for w in q_doc}\n",
    "# PRON is such as me/it/you\n",
    "# lemma_ : cats -> cat\n",
    "\n",
    "question_tokens_set = set(question_tokens)\n",
    "question_tokens_lower_set = set(question_tokens_lower)\n",
    "match_origin = [w in question_tokens_set for w in context_tokens]\n",
    "match_lower = [w in question_tokens_lower_set for w in context_tokens_lower]\n",
    "match_lemma = [(w.lemma_ if w.lemma_ != '-PRON-' else w.text.lower()) in question_lemma for w in c_doc]\n",
    "# term frequency in document\n",
    "counter_ = collections.Counter(context_tokens_lower)\n",
    "total = len(context_tokens_lower)\n",
    "context_tf = [counter_[w] / total for w in context_tokens_lower]\n",
    "context_features = list(zip(match_origin, match_lower, match_lemma, context_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RB',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'POS',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'CC',\n",
       " 'VBG',\n",
       " 'PRP',\n",
       " ',',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '``',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'PRP',\n",
       " 'NNP',\n",
       " \"''\",\n",
       " '.',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'NNP',\n",
       " 'WRB',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'RB',\n",
       " 'VBD',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'CD',\n",
       " '.',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '-LRB-',\n",
       " 'CC',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'WDT',\n",
       " 'VBZ',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " '-RRB-',\n",
       " ',',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " ',',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " '.']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example\n",
    "context_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.028169014084507043),\n",
       " (False, False, False, 0.02112676056338028),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.02112676056338028),\n",
       " (False, False, False, 0.056338028169014086),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (True, True, True, 0.014084507042253521),\n",
       " (True, True, True, 0.02112676056338028),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (True, True, True, 0.02112676056338028),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.056338028169014086),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.028169014084507043),\n",
       " (False, False, False, 0.02112676056338028),\n",
       " (False, False, False, 0.028169014084507043),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.02112676056338028),\n",
       " (False, False, False, 0.056338028169014086),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, True, True, 0.014084507042253521),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.028169014084507043),\n",
       " (False, False, False, 0.02112676056338028),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.056338028169014086),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.056338028169014086),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.028169014084507043),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.056338028169014086),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (True, True, True, 0.007042253521126761),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (True, True, True, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (True, True, True, 0.014084507042253521),\n",
       " (True, True, True, 0.02112676056338028),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, True, 0.007042253521126761),\n",
       " (False, True, True, 0.014084507042253521),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (True, True, True, 0.02112676056338028),\n",
       " (True, True, True, 0.007042253521126761),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.056338028169014086),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.028169014084507043),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.028169014084507043),\n",
       " (True, True, True, 0.02112676056338028),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.028169014084507043),\n",
       " (True, True, True, 0.1056338028169014),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.014084507042253521),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (False, False, False, 0.04929577464788732),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.04225352112676056),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.007042253521126761),\n",
       " (False, False, False, 0.02112676056338028),\n",
       " (False, False, False, 0.056338028169014086),\n",
       " (True, True, True, 0.02112676056338028),\n",
       " (False, False, False, 0.04929577464788732)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_features\n",
    "# a new feature engineering: make the probablity of answer lager somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_answer(row):\n",
    "    token_span = row[-4]\n",
    "    starts, ends = zip(*token_span)\n",
    "    answer_start = row[-2]\n",
    "    answer_end = row[-1]\n",
    "    try:\n",
    "        return row[:-3] + (starts.index(answer_start), ends.index(answer_end))\n",
    "    except ValueError:\n",
    "        return row[:-3] + (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_span = context_token_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starts, ends = zip(*token_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = 'Saint Bernadette Soubirous'\n",
    "answer_start = 515\n",
    "answer_end = answer_start + len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts.index(answer_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ends.index(answer_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pos tagging count for context\n",
    "counter_tag = collections.Counter(w for w in context_tags) #context_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({\"''\": 1,\n",
       "         ',': 6,\n",
       "         '-LRB-': 1,\n",
       "         '-RRB-': 1,\n",
       "         '.': 7,\n",
       "         'CC': 4,\n",
       "         'CD': 2,\n",
       "         'DT': 22,\n",
       "         'IN': 20,\n",
       "         'JJ': 7,\n",
       "         'NN': 20,\n",
       "         'NNP': 27,\n",
       "         'NNS': 2,\n",
       "         'POS': 1,\n",
       "         'PRP': 3,\n",
       "         'RB': 5,\n",
       "         'VBD': 1,\n",
       "         'VBG': 1,\n",
       "         'VBZ': 8,\n",
       "         'WDT': 1,\n",
       "         'WRB': 1,\n",
       "         '``': 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_tag = sorted(counter_tag, key=counter_tag.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag2id = {w: i for i, w in enumerate(vocab_tag)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"''\": 16,\n",
       " ',': 7,\n",
       " '-LRB-': 19,\n",
       " '-RRB-': 21,\n",
       " '.': 6,\n",
       " 'CC': 9,\n",
       " 'CD': 12,\n",
       " 'DT': 1,\n",
       " 'IN': 3,\n",
       " 'JJ': 5,\n",
       " 'NN': 2,\n",
       " 'NNP': 0,\n",
       " 'NNS': 11,\n",
       " 'POS': 13,\n",
       " 'PRP': 10,\n",
       " 'RB': 8,\n",
       " 'VBD': 18,\n",
       " 'VBG': 14,\n",
       " 'VBZ': 4,\n",
       " 'WDT': 20,\n",
       " 'WRB': 17,\n",
       " '``': 15}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# largest count with small index number\n",
    "tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import msgpack\n",
    "with open('SQuAD/meta.msgpack', 'rb') as f:\n",
    "    meta = msgpack.load(f, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "embedding = torch.Tensor(meta['char_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([91187, 100])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of pos tag given by spacy \n",
    "len(meta['vocab_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of NER tag given by spacy\n",
    "len(meta['vocab_ent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " ',',\n",
       " '.',\n",
       " 'CC',\n",
       " 'VBD',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " 'CD',\n",
       " 'VB',\n",
       " 'VBZ',\n",
       " 'VBG',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " '-RRB-',\n",
       " 'HYPH',\n",
       " '-LRB-',\n",
       " 'PRP$',\n",
       " 'POS',\n",
       " 'WDT',\n",
       " \"''\",\n",
       " '``',\n",
       " 'MD',\n",
       " 'NNPS',\n",
       " ':',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'WRB',\n",
       " 'WP',\n",
       " 'RP',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'EX',\n",
       " '$',\n",
       " 'SYM',\n",
       " 'FW',\n",
       " 'NFP',\n",
       " 'AFX',\n",
       " 'PDT',\n",
       " 'WP$',\n",
       " 'UH',\n",
       " 'LS',\n",
       " 'SP',\n",
       " 'XX',\n",
       " 'ADD']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos tag\n",
    "meta['vocab_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'ORG',\n",
       " 'DATE',\n",
       " 'PERSON',\n",
       " 'GPE',\n",
       " 'CARDINAL',\n",
       " 'NORP',\n",
       " 'LOC',\n",
       " 'WORK_OF_ART',\n",
       " 'PERCENT',\n",
       " 'EVENT',\n",
       " 'ORDINAL',\n",
       " 'MONEY',\n",
       " 'FAC',\n",
       " 'QUANTITY',\n",
       " 'LAW',\n",
       " 'TIME',\n",
       " 'LANGUAGE',\n",
       " 'PRODUCT']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['vocab_ent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SQuAD/data.msgpack', 'rb') as f:\n",
    "    data = msgpack.load(f, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5733be284776f41900661182',\n",
       " [55739,\n",
       "  18,\n",
       "  3,\n",
       "  137,\n",
       "  47,\n",
       "  12,\n",
       "  523,\n",
       "  991,\n",
       "  216,\n",
       "  78437,\n",
       "  3,\n",
       "  5448,\n",
       "  2422,\n",
       "  13,\n",
       "  1676,\n",
       "  10685,\n",
       "  9,\n",
       "  12,\n",
       "  6226,\n",
       "  4716,\n",
       "  5,\n",
       "  3,\n",
       "  3696,\n",
       "  711,\n",
       "  216,\n",
       "  26397,\n",
       "  6,\n",
       "  2070,\n",
       "  5,\n",
       "  3,\n",
       "  5448,\n",
       "  2422,\n",
       "  17,\n",
       "  6409,\n",
       "  50,\n",
       "  18,\n",
       "  9,\n",
       "  12,\n",
       "  758,\n",
       "  4716,\n",
       "  5,\n",
       "  2329,\n",
       "  28,\n",
       "  3114,\n",
       "  78498,\n",
       "  28,\n",
       "  3,\n",
       "  5904,\n",
       "  39,\n",
       "  73457,\n",
       "  16884,\n",
       "  7744,\n",
       "  78000,\n",
       "  39,\n",
       "  216,\n",
       "  23707,\n",
       "  7,\n",
       "  3,\n",
       "  5448,\n",
       "  2422,\n",
       "  9,\n",
       "  3,\n",
       "  4483,\n",
       "  5,\n",
       "  3,\n",
       "  9842,\n",
       "  4840,\n",
       "  216,\n",
       "  26397,\n",
       "  1584,\n",
       "  3,\n",
       "  10535,\n",
       "  9,\n",
       "  3,\n",
       "  18336,\n",
       "  18,\n",
       "  12,\n",
       "  12033,\n",
       "  122,\n",
       "  5,\n",
       "  5267,\n",
       "  17,\n",
       "  9167,\n",
       "  216,\n",
       "  2263,\n",
       "  9,\n",
       "  12,\n",
       "  12551,\n",
       "  5,\n",
       "  3,\n",
       "  63227,\n",
       "  45,\n",
       "  18335,\n",
       "  18,\n",
       "  197,\n",
       "  110,\n",
       "  3,\n",
       "  3696,\n",
       "  711,\n",
       "  43956,\n",
       "  1911,\n",
       "  7,\n",
       "  642,\n",
       "  49069,\n",
       "  49084,\n",
       "  6,\n",
       "  8898,\n",
       "  216,\n",
       "  217,\n",
       "  3,\n",
       "  140,\n",
       "  5,\n",
       "  3,\n",
       "  146,\n",
       "  2053,\n",
       "  920,\n",
       "  17,\n",
       "  6,\n",
       "  12,\n",
       "  1503,\n",
       "  392,\n",
       "  22,\n",
       "  2942,\n",
       "  243,\n",
       "  801,\n",
       "  6547,\n",
       "  17,\n",
       "  3,\n",
       "  4660,\n",
       "  14014,\n",
       "  825,\n",
       "  18,\n",
       "  9,\n",
       "  12,\n",
       "  2737,\n",
       "  18,\n",
       "  205,\n",
       "  2739,\n",
       "  4716,\n",
       "  5,\n",
       "  711,\n",
       "  216],\n",
       " [[False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.028169014084507043],\n",
       "  [False, False, False, 0.02112676056338028],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.02112676056338028],\n",
       "  [False, False, False, 0.056338028169014086],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [True, True, True, 0.014084507042253521],\n",
       "  [True, True, True, 0.02112676056338028],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [True, True, True, 0.02112676056338028],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.056338028169014086],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.028169014084507043],\n",
       "  [False, False, False, 0.02112676056338028],\n",
       "  [False, False, False, 0.028169014084507043],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.02112676056338028],\n",
       "  [False, False, False, 0.056338028169014086],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, True, True, 0.014084507042253521],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.028169014084507043],\n",
       "  [False, False, False, 0.02112676056338028],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.056338028169014086],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.056338028169014086],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.028169014084507043],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.056338028169014086],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [True, True, True, 0.007042253521126761],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [True, True, True, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [True, True, True, 0.014084507042253521],\n",
       "  [True, True, True, 0.02112676056338028],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, True, 0.007042253521126761],\n",
       "  [False, True, True, 0.014084507042253521],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [True, True, True, 0.02112676056338028],\n",
       "  [True, True, True, 0.007042253521126761],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.056338028169014086],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.028169014084507043],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.028169014084507043],\n",
       "  [True, True, True, 0.02112676056338028],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.028169014084507043],\n",
       "  [True, True, True, 0.1056338028169014],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.014084507042253521],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [False, False, False, 0.04929577464788732],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.04225352112676056],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.007042253521126761],\n",
       "  [False, False, False, 0.02112676056338028],\n",
       "  [False, False, False, 0.056338028169014086],\n",
       "  [True, True, True, 0.02112676056338028],\n",
       "  [False, False, False, 0.04929577464788732]],\n",
       " [10,\n",
       "  6,\n",
       "  3,\n",
       "  0,\n",
       "  14,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  7,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  23,\n",
       "  0,\n",
       "  0,\n",
       "  14,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  7,\n",
       "  10,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  8,\n",
       "  15,\n",
       "  16,\n",
       "  6,\n",
       "  14,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  26,\n",
       "  2,\n",
       "  2,\n",
       "  16,\n",
       "  2,\n",
       "  25,\n",
       "  7,\n",
       "  10,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  14,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  7,\n",
       "  10,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  14,\n",
       "  3,\n",
       "  2,\n",
       "  6,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  8,\n",
       "  0,\n",
       "  7,\n",
       "  16,\n",
       "  14,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  6,\n",
       "  2,\n",
       "  32,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  10,\n",
       "  9,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  12,\n",
       "  7,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  21,\n",
       "  8,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  24,\n",
       "  14,\n",
       "  1,\n",
       "  12,\n",
       "  5,\n",
       "  8,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  19,\n",
       "  6,\n",
       "  14,\n",
       "  3,\n",
       "  4,\n",
       "  6,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  7],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0],\n",
       " [224, 213, 10, 3, 3696, 711, 5692, 625, 6, 8898, 6, 18335, 197, 2],\n",
       " 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " [[0, 15],\n",
       "  [15, 16],\n",
       "  [17, 20],\n",
       "  [21, 27],\n",
       "  [28, 31],\n",
       "  [32, 33],\n",
       "  [34, 42],\n",
       "  [43, 52],\n",
       "  [52, 53],\n",
       "  [54, 58],\n",
       "  [59, 62],\n",
       "  [63, 67],\n",
       "  [68, 76],\n",
       "  [76, 78],\n",
       "  [79, 83],\n",
       "  [84, 88],\n",
       "  [89, 91],\n",
       "  [92, 93],\n",
       "  [94, 100],\n",
       "  [101, 107],\n",
       "  [108, 110],\n",
       "  [111, 114],\n",
       "  [115, 121],\n",
       "  [122, 126],\n",
       "  [126, 127],\n",
       "  [128, 139],\n",
       "  [140, 142],\n",
       "  [143, 148],\n",
       "  [149, 151],\n",
       "  [152, 155],\n",
       "  [156, 160],\n",
       "  [161, 169],\n",
       "  [170, 173],\n",
       "  [174, 180],\n",
       "  [181, 183],\n",
       "  [183, 184],\n",
       "  [185, 187],\n",
       "  [188, 189],\n",
       "  [190, 196],\n",
       "  [197, 203],\n",
       "  [204, 206],\n",
       "  [207, 213],\n",
       "  [214, 218],\n",
       "  [219, 223],\n",
       "  [224, 232],\n",
       "  [233, 237],\n",
       "  [238, 241],\n",
       "  [242, 248],\n",
       "  [249, 250],\n",
       "  [250, 256],\n",
       "  [257, 259],\n",
       "  [260, 262],\n",
       "  [263, 268],\n",
       "  [268, 269],\n",
       "  [269, 270],\n",
       "  [271, 275],\n",
       "  [276, 278],\n",
       "  [279, 282],\n",
       "  [283, 287],\n",
       "  [288, 296],\n",
       "  [297, 299],\n",
       "  [300, 303],\n",
       "  [304, 312],\n",
       "  [313, 315],\n",
       "  [316, 319],\n",
       "  [320, 326],\n",
       "  [327, 332],\n",
       "  [332, 333],\n",
       "  [334, 345],\n",
       "  [346, 352],\n",
       "  [353, 356],\n",
       "  [357, 365],\n",
       "  [366, 368],\n",
       "  [369, 372],\n",
       "  [373, 379],\n",
       "  [379, 380],\n",
       "  [381, 382],\n",
       "  [383, 389],\n",
       "  [390, 395],\n",
       "  [396, 398],\n",
       "  [399, 405],\n",
       "  [406, 409],\n",
       "  [410, 420],\n",
       "  [420, 421],\n",
       "  [422, 424],\n",
       "  [425, 427],\n",
       "  [428, 429],\n",
       "  [430, 437],\n",
       "  [438, 440],\n",
       "  [441, 444],\n",
       "  [445, 451],\n",
       "  [452, 454],\n",
       "  [455, 462],\n",
       "  [462, 463],\n",
       "  [464, 470],\n",
       "  [471, 476],\n",
       "  [477, 480],\n",
       "  [481, 487],\n",
       "  [488, 492],\n",
       "  [493, 502],\n",
       "  [503, 511],\n",
       "  [512, 514],\n",
       "  [515, 520],\n",
       "  [521, 531],\n",
       "  [532, 541],\n",
       "  [542, 544],\n",
       "  [545, 549],\n",
       "  [549, 550],\n",
       "  [551, 553],\n",
       "  [554, 557],\n",
       "  [558, 561],\n",
       "  [562, 564],\n",
       "  [565, 568],\n",
       "  [569, 573],\n",
       "  [574, 579],\n",
       "  [580, 581],\n",
       "  [581, 584],\n",
       "  [585, 587],\n",
       "  [588, 589],\n",
       "  [590, 596],\n",
       "  [597, 601],\n",
       "  [602, 606],\n",
       "  [607, 615],\n",
       "  [616, 623],\n",
       "  [624, 625],\n",
       "  [626, 633],\n",
       "  [634, 637],\n",
       "  [638, 641],\n",
       "  [642, 646],\n",
       "  [647, 651],\n",
       "  [651, 652],\n",
       "  [652, 653],\n",
       "  [654, 656],\n",
       "  [657, 658],\n",
       "  [659, 665],\n",
       "  [665, 666],\n",
       "  [667, 673],\n",
       "  [674, 679],\n",
       "  [680, 686],\n",
       "  [687, 689],\n",
       "  [690, 694],\n",
       "  [694, 695]],\n",
       " 102,\n",
       " 104]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train: id, context_id, context_features, tag_id, ent_id,\n",
    "#        question_id, context, context_token_span, answer_start, answer_end\n",
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context\n",
    "data['train'][0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example cotext id \n",
    "data['train'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 14,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 23,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 15,\n",
       " 16,\n",
       " 6,\n",
       " 14,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 26,\n",
       " 2,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 25,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 14,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 10,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 14,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 16,\n",
       " 14,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 32,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 12,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 21,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 24,\n",
       " 14,\n",
       " 1,\n",
       " 12,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 19,\n",
       " 6,\n",
       " 14,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 7]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example pos tag_id\n",
    "data['train'][0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['vocab'][53946]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RB'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['vocab_tag'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.068894,\n",
       " 0.38769,\n",
       " -0.2612,\n",
       " -0.13737,\n",
       " -0.2154,\n",
       " 0.16583,\n",
       " -0.057185,\n",
       " -0.1818,\n",
       " -0.091393,\n",
       " 3.0152,\n",
       " 0.0080077,\n",
       " -0.14678,\n",
       " 0.59703,\n",
       " 0.13855,\n",
       " -0.38471,\n",
       " -0.18226,\n",
       " -0.048115,\n",
       " 0.19229,\n",
       " -0.39827,\n",
       " -0.069427,\n",
       " 0.44313,\n",
       " 0.039526,\n",
       " 0.12246,\n",
       " -0.0095958,\n",
       " -0.27647,\n",
       " 0.052025,\n",
       " -0.20317,\n",
       " -0.24843,\n",
       " 0.18102,\n",
       " -0.146,\n",
       " -0.18892,\n",
       " 0.29503,\n",
       " 0.033175,\n",
       " 0.017062,\n",
       " -0.050974,\n",
       " -0.10416,\n",
       " -0.083443,\n",
       " -0.036962,\n",
       " -0.31562,\n",
       " -0.25156,\n",
       " -0.078766,\n",
       " 0.3288,\n",
       " 0.0047974,\n",
       " -0.17029,\n",
       " 0.25234,\n",
       " -0.043896,\n",
       " -0.3515,\n",
       " 0.044745,\n",
       " 0.30536,\n",
       " 0.0063232,\n",
       " -0.13202,\n",
       " -0.0034639,\n",
       " 0.23588,\n",
       " 0.080575,\n",
       " 0.32261,\n",
       " -0.11584,\n",
       " -0.079779,\n",
       " -0.21162,\n",
       " 0.032221,\n",
       " -0.023761,\n",
       " -0.060977,\n",
       " -0.24384,\n",
       " 0.092764,\n",
       " 0.59417,\n",
       " 0.050349,\n",
       " -0.076585,\n",
       " 0.024472,\n",
       " 0.063355,\n",
       " 0.52163,\n",
       " 0.14607,\n",
       " 0.39275,\n",
       " 0.40531,\n",
       " 0.1003,\n",
       " -0.042093,\n",
       " 0.22654,\n",
       " 0.12735,\n",
       " -0.0407,\n",
       " -0.21567,\n",
       " -0.073999,\n",
       " 0.20608,\n",
       " 0.052384,\n",
       " -0.053651,\n",
       " -0.068521,\n",
       " -0.19867,\n",
       " 0.032769,\n",
       " -0.2159,\n",
       " 0.24419,\n",
       " -0.88759,\n",
       " 0.079682,\n",
       " 0.1556,\n",
       " -0.17208,\n",
       " -0.13209,\n",
       " -0.293,\n",
       " 0.30658,\n",
       " 0.68035,\n",
       " -0.10776,\n",
       " 0.3552,\n",
       " -0.040542,\n",
       " 0.056704,\n",
       " 0.23509,\n",
       " -0.18616,\n",
       " 0.36344,\n",
       " 0.1102,\n",
       " -0.19391,\n",
       " 0.10941,\n",
       " -0.61226,\n",
       " 0.10745,\n",
       " -0.27369,\n",
       " -0.057156,\n",
       " -0.014424,\n",
       " 0.06523,\n",
       " 0.040382,\n",
       " 0.099708,\n",
       " -0.20316,\n",
       " 0.24752,\n",
       " -0.38636,\n",
       " 0.41649,\n",
       " -0.022005,\n",
       " 0.028479,\n",
       " 0.037521,\n",
       " 0.30145,\n",
       " -0.19554,\n",
       " 0.21607,\n",
       " -0.0021629,\n",
       " -0.091473,\n",
       " 0.13047,\n",
       " -0.25666,\n",
       " -0.41818,\n",
       " 0.053018,\n",
       " 0.12377,\n",
       " 0.18438,\n",
       " 0.13254,\n",
       " -0.14962,\n",
       " 0.11432,\n",
       " 0.32478,\n",
       " -0.069747,\n",
       " 0.10825,\n",
       " 0.13107,\n",
       " -0.018367,\n",
       " -0.12022,\n",
       " -2.0446,\n",
       " -0.0063927,\n",
       " 0.18149,\n",
       " -0.053651,\n",
       " 0.17999,\n",
       " 0.045148,\n",
       " -0.49186,\n",
       " 0.071751,\n",
       " -0.13357,\n",
       " -0.15676,\n",
       " 0.043813,\n",
       " 0.035569,\n",
       " 0.09355,\n",
       " 0.11504,\n",
       " -0.070877,\n",
       " -0.37313,\n",
       " -0.16702,\n",
       " -0.17217,\n",
       " 0.24716,\n",
       " 0.058633,\n",
       " -0.38154,\n",
       " 0.026736,\n",
       " -0.35032,\n",
       " -0.1229,\n",
       " -0.31388,\n",
       " -0.083798,\n",
       " -0.1386,\n",
       " -0.15093,\n",
       " 0.17949,\n",
       " -0.042628,\n",
       " -0.12303,\n",
       " -0.067392,\n",
       " -0.017052,\n",
       " -0.46894,\n",
       " -0.27076,\n",
       " 0.013046,\n",
       " -0.031676,\n",
       " 0.07704,\n",
       " 0.044534,\n",
       " -0.34076,\n",
       " -0.1318,\n",
       " -0.11474,\n",
       " -0.46655,\n",
       " -0.0065947,\n",
       " 0.074149,\n",
       " -0.028732,\n",
       " -0.083976,\n",
       " 0.12192,\n",
       " 0.084805,\n",
       " 0.19186,\n",
       " 0.29073,\n",
       " 0.10824,\n",
       " -0.48059,\n",
       " -0.02435,\n",
       " 0.080575,\n",
       " 0.16651,\n",
       " 0.070393,\n",
       " -0.34514,\n",
       " 0.18124,\n",
       " 0.25638,\n",
       " -0.20278,\n",
       " -0.013885,\n",
       " -0.050953,\n",
       " -0.3456,\n",
       " 0.25451,\n",
       " 0.07556,\n",
       " 0.24931,\n",
       " -0.21375,\n",
       " 0.42524,\n",
       " 0.31741,\n",
       " 0.3478,\n",
       " 0.11065,\n",
       " -0.0098968,\n",
       " -0.12733,\n",
       " 0.085349,\n",
       " 0.048286,\n",
       " -0.18867,\n",
       " -0.20865,\n",
       " -0.08543,\n",
       " 0.010498,\n",
       " 0.25702,\n",
       " 0.098603,\n",
       " -0.15663,\n",
       " 0.13255,\n",
       " -0.096963,\n",
       " 0.37287,\n",
       " 0.042068,\n",
       " 0.0015415,\n",
       " -0.08682,\n",
       " 0.060504,\n",
       " -0.23958,\n",
       " 0.080184,\n",
       " 0.074252,\n",
       " 0.15825,\n",
       " -0.20592,\n",
       " -0.1787,\n",
       " 0.26432,\n",
       " -0.12007,\n",
       " 0.056193,\n",
       " 0.16916,\n",
       " -0.1106,\n",
       " -0.029442,\n",
       " -0.038349,\n",
       " 0.32298,\n",
       " 0.13419,\n",
       " -0.31025,\n",
       " -0.13205,\n",
       " -0.045077,\n",
       " -0.45831,\n",
       " 0.4171,\n",
       " 0.18851,\n",
       " -0.14794,\n",
       " -0.3806,\n",
       " -0.2004,\n",
       " 0.049388,\n",
       " -0.2728,\n",
       " -0.09721,\n",
       " 0.012075,\n",
       " 0.10529,\n",
       " 0.16312,\n",
       " 0.41713,\n",
       " 0.20106,\n",
       " -0.075969,\n",
       " 0.11092,\n",
       " 0.19831,\n",
       " 0.28921,\n",
       " 0.1226,\n",
       " 0.15835,\n",
       " 0.13568,\n",
       " 0.49098,\n",
       " 0.52886,\n",
       " 0.1957,\n",
       " 0.27019,\n",
       " -0.18661,\n",
       " -0.29612,\n",
       " 0.12648,\n",
       " -0.20609,\n",
       " -0.30811,\n",
       " -0.087578,\n",
       " 0.34066,\n",
       " 0.023827,\n",
       " 0.10351,\n",
       " 0.15046,\n",
       " 0.2493,\n",
       " -0.18511,\n",
       " -0.063229,\n",
       " 0.1456,\n",
       " 0.22438,\n",
       " 0.16841,\n",
       " 0.091937,\n",
       " -0.23429,\n",
       " 0.19559,\n",
       " 0.16045,\n",
       " 0.2012,\n",
       " 0.33907,\n",
       " -0.26314,\n",
       " -0.14529,\n",
       " 0.19304,\n",
       " 0.37526,\n",
       " 0.14579]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['embedding'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(meta['vocab']) == len(meta['char_embeddings']) ==91187"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 874474\n",
    "d_emb = 100\n",
    "seen = set()\n",
    "fin_name = 'char/charNgram.txt'\n",
    "with open(fin_name, 'r') as ftxt:\n",
    "    content = ftxt.read()\n",
    "    lines = content.splitlines()\n",
    "    batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    elems = line.rstrip().split()\n",
    "    vec = [float(n) for n in elems[-d_emb:]]\n",
    "    word = ' '.join(elems[:-d_emb])\n",
    "    if word in seen:\n",
    "        continue\n",
    "    seen.add(word)\n",
    "    batch.append((word, vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngrams(sentence, n):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        list: a list of lists of words corresponding to the ngrams in the sentence.\n",
    "    \"\"\"\n",
    "    return [sentence[i:i+n] for i in range(len(sentence)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emb(w, default='zero'):\n",
    "    assert default == 'zero', 'only zero default is supported for character embeddings'\n",
    "    chars = ['#BEGIN#'] + list(w) + ['#END#']\n",
    "    embs = np.zeros(d_emb, dtype=np.float32)\n",
    "    match = {}\n",
    "    for i in [2, 3, 4]:\n",
    "        grams = ngrams(chars, i)\n",
    "        for g in grams:\n",
    "            g = '{}gram-{}'.format(i, ''.join(g))\n",
    "            e = self.lookup(g)\n",
    "            if e is not None:\n",
    "                match[g] = np.array(e, np.float32)\n",
    "    if match:\n",
    "        embs = sum(match.values()) / len(match)\n",
    "    return embs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['#BEGIN#'] + list('cat') + ['#END#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = np.zeros(d_emb, dtype=np.float32)\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = {}\n",
    "for i in [2, 3, 4]:\n",
    "    grams = ngrams(chars, i)\n",
    "    for g in grams:\n",
    "        g = '{}gram-{}'.format(i, ''.join(g))\n",
    "        print(g)\n",
    "        #e = lookup(g)\n",
    "        #if e is not None:\n",
    "        #    match[g] = np.array(e, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepro.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_file = 'SQuAD/train-v1.1.json'\n",
    "import json\n",
    "\n",
    "def flatten_json(data_file, mode):\n",
    "    \"\"\"Flatten each article in training data.\"\"\"\n",
    "    with open(data_file) as f:\n",
    "        data = json.load(f)['data']\n",
    "    rows = []\n",
    "    for article in data:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                id_, question, answers = qa['id'], qa['question'], qa['answers']\n",
    "                if mode == 'train':\n",
    "                    answer = answers[0]['text']  # in training data there's only one answer\n",
    "                    answer_start = answers[0]['answer_start'] # char level length\n",
    "                    answer_end = answer_start + len(answer) # char level lenght\n",
    "                    rows.append((id_, context, question, answer, answer_start, answer_end))\n",
    "                else:  # mode == 'dev'\n",
    "                    answers = [a['text'] for a in answers]\n",
    "                    rows.append((id_, context, question, answers))\n",
    "    return rows\n",
    "\n",
    "\n",
    "train = flatten_json(trn_file, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5733be284776f4190066117f',\n",
       " 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'What is in front of the Notre Dame Main Building?',\n",
       " 'a copper statue of Christ',\n",
       " 188,\n",
       " 213)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_spaces(text):\n",
    "    \"\"\"normalize spaces in a string.\"\"\"\n",
    "    text = re.sub(r'\\s', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize('NFD', text)\n",
    "\n",
    "\n",
    "nlp = None\n",
    "\n",
    "\n",
    "def init():\n",
    "    \"\"\"initialize spacy in each process\"\"\"\n",
    "    '''\n",
    "    'en': Noun chunks are \"base noun phrases\"  flat phrases that have a noun as their head.\n",
    "    parser=False or disable=['parser'] : don't need any of the syntactic information,\n",
    "                                        and will make spaCy load and run much faster.\n",
    "    '''\n",
    "    global nlp\n",
    "    nlp = spacy.load('en', parser=False)\n",
    "\n",
    "\n",
    "def annotate(row):\n",
    "    global nlp\n",
    "    id_, context, question = row[:3]\n",
    "    q_doc = nlp(clean_spaces(question))\n",
    "    c_doc = nlp(clean_spaces(context))\n",
    "    question_tokens = [normalize_text(w.text) for w in q_doc]\n",
    "    context_tokens = [normalize_text(w.text) for w in c_doc]\n",
    "    question_tokens_lower = [w.lower() for w in question_tokens]\n",
    "    context_tokens_lower = [w.lower() for w in context_tokens]\n",
    "    context_token_span = [(w.idx, w.idx + len(w.text)) for w in c_doc] # the lenghth of each tokens\n",
    "    context_tags = [w.tag_ for w in c_doc] # POS tagging\n",
    "    context_ents = [w.ent_type_ for w in c_doc] # NER tagging\n",
    "\n",
    "    question_lemma = {w.lemma_ if w.lemma_ != '-PRON-' else w.text.lower() for w in q_doc}\n",
    "    # PRON is such as me/it/you\n",
    "    # lemma_ : cats -> cat\n",
    "\n",
    "    question_tokens_set = set(question_tokens)\n",
    "    question_tokens_lower_set = set(question_tokens_lower)\n",
    "    match_origin = [w in question_tokens_set for w in context_tokens]\n",
    "    match_lower = [w in question_tokens_lower_set for w in context_tokens_lower]\n",
    "    match_lemma = [(w.lemma_ if w.lemma_ != '-PRON-' else w.text.lower()) in question_lemma for w in c_doc]\n",
    "    # term frequency in document\n",
    "    counter_ = collections.Counter(context_tokens_lower)\n",
    "    total = len(context_tokens_lower)\n",
    "    # frequent feature\n",
    "    context_tf = [counter_[w] / total for w in context_tokens_lower]\n",
    "    # exact match feature refering to the paper\n",
    "    context_features = list(zip(match_origin, match_lower, match_lemma, context_tf))\n",
    "    if not True:\n",
    "        context_tokens = context_tokens_lower\n",
    "        question_tokens = question_tokens_lower\n",
    "    return (id_, context_tokens, context_features, context_tags, context_ents,\n",
    "            question_tokens, context, context_token_span) + row[3:]\n",
    "\n",
    "\n",
    "def index_answer(row):\n",
    "    token_span = row[-4] #context_token_span\n",
    "    starts, ends = zip(*token_span)\n",
    "    answer_start = row[-2]\n",
    "    answer_end = row[-1]\n",
    "    try:\n",
    "        return row[:-3] + (starts.index(answer_start), ends.index(answer_end))\n",
    "    except ValueError:\n",
    "        return row[:-3] + (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5733be284776f4190066117f',\n",
       " 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'What is in front of the Notre Dame Main Building?',\n",
       " 'a copper statue of Christ',\n",
       " 188,\n",
       " 213)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', parser=False)\n",
    "train_ann = annotate(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5733be284776f4190066117f',\n",
       " ['Architecturally',\n",
       "  ',',\n",
       "  'the',\n",
       "  'school',\n",
       "  'has',\n",
       "  'a',\n",
       "  'Catholic',\n",
       "  'character',\n",
       "  '.',\n",
       "  'Atop',\n",
       "  'the',\n",
       "  'Main',\n",
       "  'Building',\n",
       "  \"'s\",\n",
       "  'gold',\n",
       "  'dome',\n",
       "  'is',\n",
       "  'a',\n",
       "  'golden',\n",
       "  'statue',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Virgin',\n",
       "  'Mary',\n",
       "  '.',\n",
       "  'Immediately',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Main',\n",
       "  'Building',\n",
       "  'and',\n",
       "  'facing',\n",
       "  'it',\n",
       "  ',',\n",
       "  'is',\n",
       "  'a',\n",
       "  'copper',\n",
       "  'statue',\n",
       "  'of',\n",
       "  'Christ',\n",
       "  'with',\n",
       "  'arms',\n",
       "  'upraised',\n",
       "  'with',\n",
       "  'the',\n",
       "  'legend',\n",
       "  '\"',\n",
       "  'Venite',\n",
       "  'Ad',\n",
       "  'Me',\n",
       "  'Omnes',\n",
       "  '\"',\n",
       "  '.',\n",
       "  'Next',\n",
       "  'to',\n",
       "  'the',\n",
       "  'Main',\n",
       "  'Building',\n",
       "  'is',\n",
       "  'the',\n",
       "  'Basilica',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Sacred',\n",
       "  'Heart',\n",
       "  '.',\n",
       "  'Immediately',\n",
       "  'behind',\n",
       "  'the',\n",
       "  'basilica',\n",
       "  'is',\n",
       "  'the',\n",
       "  'Grotto',\n",
       "  ',',\n",
       "  'a',\n",
       "  'Marian',\n",
       "  'place',\n",
       "  'of',\n",
       "  'prayer',\n",
       "  'and',\n",
       "  'reflection',\n",
       "  '.',\n",
       "  'It',\n",
       "  'is',\n",
       "  'a',\n",
       "  'replica',\n",
       "  'of',\n",
       "  'the',\n",
       "  'grotto',\n",
       "  'at',\n",
       "  'Lourdes',\n",
       "  ',',\n",
       "  'France',\n",
       "  'where',\n",
       "  'the',\n",
       "  'Virgin',\n",
       "  'Mary',\n",
       "  'reputedly',\n",
       "  'appeared',\n",
       "  'to',\n",
       "  'Saint',\n",
       "  'Bernadette',\n",
       "  'Soubirous',\n",
       "  'in',\n",
       "  '1858',\n",
       "  '.',\n",
       "  'At',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'the',\n",
       "  'main',\n",
       "  'drive',\n",
       "  '(',\n",
       "  'and',\n",
       "  'in',\n",
       "  'a',\n",
       "  'direct',\n",
       "  'line',\n",
       "  'that',\n",
       "  'connects',\n",
       "  'through',\n",
       "  '3',\n",
       "  'statues',\n",
       "  'and',\n",
       "  'the',\n",
       "  'Gold',\n",
       "  'Dome',\n",
       "  ')',\n",
       "  ',',\n",
       "  'is',\n",
       "  'a',\n",
       "  'simple',\n",
       "  ',',\n",
       "  'modern',\n",
       "  'stone',\n",
       "  'statue',\n",
       "  'of',\n",
       "  'Mary',\n",
       "  '.'],\n",
       " [(False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.04225352112676056),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (True, True, True, 0.028169014084507043),\n",
       "  (True, True, True, 0.02112676056338028),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (True, True, True, 0.04225352112676056),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.02112676056338028),\n",
       "  (True, True, True, 0.056338028169014086),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.02112676056338028),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (True, True, True, 0.02112676056338028),\n",
       "  (True, True, True, 0.007042253521126761),\n",
       "  (True, True, True, 0.056338028169014086),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (True, True, True, 0.028169014084507043),\n",
       "  (True, True, True, 0.02112676056338028),\n",
       "  (False, False, False, 0.028169014084507043),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.04225352112676056),\n",
       "  (True, True, True, 0.04225352112676056),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.02112676056338028),\n",
       "  (True, True, True, 0.056338028169014086),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (True, True, True, 0.028169014084507043),\n",
       "  (True, True, True, 0.02112676056338028),\n",
       "  (True, True, True, 0.04225352112676056),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (True, True, True, 0.056338028169014086),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (True, True, True, 0.04225352112676056),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.04225352112676056),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (True, True, True, 0.056338028169014086),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.028169014084507043),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (True, True, True, 0.04225352112676056),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (True, True, True, 0.056338028169014086),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.04225352112676056),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.02112676056338028),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (True, True, True, 0.02112676056338028),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (True, True, True, 0.056338028169014086),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, True, True, 0.028169014084507043),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.028169014084507043),\n",
       "  (True, True, True, 0.02112676056338028),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.028169014084507043),\n",
       "  (True, True, True, 0.1056338028169014),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.014084507042253521),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.04225352112676056),\n",
       "  (True, True, True, 0.04225352112676056),\n",
       "  (False, False, False, 0.04929577464788732),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.04225352112676056),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.007042253521126761),\n",
       "  (False, False, False, 0.02112676056338028),\n",
       "  (True, True, True, 0.056338028169014086),\n",
       "  (False, False, False, 0.02112676056338028),\n",
       "  (False, False, False, 0.04929577464788732)],\n",
       " ['RB',\n",
       "  ',',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'VBZ',\n",
       "  'DT',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  '.',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'POS',\n",
       "  'NN',\n",
       "  'NN',\n",
       "  'VBZ',\n",
       "  'DT',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  '.',\n",
       "  'RB',\n",
       "  'IN',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'CC',\n",
       "  'VBG',\n",
       "  'PRP',\n",
       "  ',',\n",
       "  'VBZ',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'NNP',\n",
       "  'IN',\n",
       "  'NNS',\n",
       "  'JJ',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  '``',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'PRP',\n",
       "  'NNP',\n",
       "  \"''\",\n",
       "  '.',\n",
       "  'RB',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'VBZ',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  '.',\n",
       "  'RB',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'VBZ',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  ',',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'NN',\n",
       "  'CC',\n",
       "  'NN',\n",
       "  '.',\n",
       "  'PRP',\n",
       "  'VBZ',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'NNP',\n",
       "  ',',\n",
       "  'NNP',\n",
       "  'WRB',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'RB',\n",
       "  'VBD',\n",
       "  'IN',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  'IN',\n",
       "  'CD',\n",
       "  '.',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  '-LRB-',\n",
       "  'CC',\n",
       "  'IN',\n",
       "  'DT',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'WDT',\n",
       "  'VBZ',\n",
       "  'IN',\n",
       "  'CD',\n",
       "  'NNS',\n",
       "  'CC',\n",
       "  'DT',\n",
       "  'NNP',\n",
       "  'NNP',\n",
       "  '-RRB-',\n",
       "  ',',\n",
       "  'VBZ',\n",
       "  'DT',\n",
       "  'JJ',\n",
       "  ',',\n",
       "  'JJ',\n",
       "  'NN',\n",
       "  'NN',\n",
       "  'IN',\n",
       "  'NNP',\n",
       "  '.'],\n",
       " ['',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'NORP',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'FAC',\n",
       "  'FAC',\n",
       "  'FAC',\n",
       "  'FAC',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'FAC',\n",
       "  'FAC',\n",
       "  'FAC',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'NORP',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'WORK_OF_ART',\n",
       "  'WORK_OF_ART',\n",
       "  'WORK_OF_ART',\n",
       "  'WORK_OF_ART',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'FAC',\n",
       "  'FAC',\n",
       "  'FAC',\n",
       "  '',\n",
       "  '',\n",
       "  'PERSON',\n",
       "  '',\n",
       "  'ORG',\n",
       "  'ORG',\n",
       "  'ORG',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'GPE',\n",
       "  '',\n",
       "  '',\n",
       "  'PERSON',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'GPE',\n",
       "  '',\n",
       "  'GPE',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'PERSON',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'PERSON',\n",
       "  'PERSON',\n",
       "  'PERSON',\n",
       "  '',\n",
       "  'DATE',\n",
       "  '',\n",
       "  '',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  'DATE',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'CARDINAL',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'PERSON',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'PERSON',\n",
       "  ''],\n",
       " ['What',\n",
       "  'is',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Notre',\n",
       "  'Dame',\n",
       "  'Main',\n",
       "  'Building',\n",
       "  '?'],\n",
       " 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " [(0, 15),\n",
       "  (15, 16),\n",
       "  (17, 20),\n",
       "  (21, 27),\n",
       "  (28, 31),\n",
       "  (32, 33),\n",
       "  (34, 42),\n",
       "  (43, 52),\n",
       "  (52, 53),\n",
       "  (54, 58),\n",
       "  (59, 62),\n",
       "  (63, 67),\n",
       "  (68, 76),\n",
       "  (76, 78),\n",
       "  (79, 83),\n",
       "  (84, 88),\n",
       "  (89, 91),\n",
       "  (92, 93),\n",
       "  (94, 100),\n",
       "  (101, 107),\n",
       "  (108, 110),\n",
       "  (111, 114),\n",
       "  (115, 121),\n",
       "  (122, 126),\n",
       "  (126, 127),\n",
       "  (128, 139),\n",
       "  (140, 142),\n",
       "  (143, 148),\n",
       "  (149, 151),\n",
       "  (152, 155),\n",
       "  (156, 160),\n",
       "  (161, 169),\n",
       "  (170, 173),\n",
       "  (174, 180),\n",
       "  (181, 183),\n",
       "  (183, 184),\n",
       "  (185, 187),\n",
       "  (188, 189),\n",
       "  (190, 196),\n",
       "  (197, 203),\n",
       "  (204, 206),\n",
       "  (207, 213),\n",
       "  (214, 218),\n",
       "  (219, 223),\n",
       "  (224, 232),\n",
       "  (233, 237),\n",
       "  (238, 241),\n",
       "  (242, 248),\n",
       "  (249, 250),\n",
       "  (250, 256),\n",
       "  (257, 259),\n",
       "  (260, 262),\n",
       "  (263, 268),\n",
       "  (268, 269),\n",
       "  (269, 270),\n",
       "  (271, 275),\n",
       "  (276, 278),\n",
       "  (279, 282),\n",
       "  (283, 287),\n",
       "  (288, 296),\n",
       "  (297, 299),\n",
       "  (300, 303),\n",
       "  (304, 312),\n",
       "  (313, 315),\n",
       "  (316, 319),\n",
       "  (320, 326),\n",
       "  (327, 332),\n",
       "  (332, 333),\n",
       "  (334, 345),\n",
       "  (346, 352),\n",
       "  (353, 356),\n",
       "  (357, 365),\n",
       "  (366, 368),\n",
       "  (369, 372),\n",
       "  (373, 379),\n",
       "  (379, 380),\n",
       "  (381, 382),\n",
       "  (383, 389),\n",
       "  (390, 395),\n",
       "  (396, 398),\n",
       "  (399, 405),\n",
       "  (406, 409),\n",
       "  (410, 420),\n",
       "  (420, 421),\n",
       "  (422, 424),\n",
       "  (425, 427),\n",
       "  (428, 429),\n",
       "  (430, 437),\n",
       "  (438, 440),\n",
       "  (441, 444),\n",
       "  (445, 451),\n",
       "  (452, 454),\n",
       "  (455, 462),\n",
       "  (462, 463),\n",
       "  (464, 470),\n",
       "  (471, 476),\n",
       "  (477, 480),\n",
       "  (481, 487),\n",
       "  (488, 492),\n",
       "  (493, 502),\n",
       "  (503, 511),\n",
       "  (512, 514),\n",
       "  (515, 520),\n",
       "  (521, 531),\n",
       "  (532, 541),\n",
       "  (542, 544),\n",
       "  (545, 549),\n",
       "  (549, 550),\n",
       "  (551, 553),\n",
       "  (554, 557),\n",
       "  (558, 561),\n",
       "  (562, 564),\n",
       "  (565, 568),\n",
       "  (569, 573),\n",
       "  (574, 579),\n",
       "  (580, 581),\n",
       "  (581, 584),\n",
       "  (585, 587),\n",
       "  (588, 589),\n",
       "  (590, 596),\n",
       "  (597, 601),\n",
       "  (602, 606),\n",
       "  (607, 615),\n",
       "  (616, 623),\n",
       "  (624, 625),\n",
       "  (626, 633),\n",
       "  (634, 637),\n",
       "  (638, 641),\n",
       "  (642, 646),\n",
       "  (647, 651),\n",
       "  (651, 652),\n",
       "  (652, 653),\n",
       "  (654, 656),\n",
       "  (657, 658),\n",
       "  (659, 665),\n",
       "  (665, 666),\n",
       "  (667, 673),\n",
       "  (674, 679),\n",
       "  (680, 686),\n",
       "  (687, 689),\n",
       "  (690, 694),\n",
       "  (694, 695)],\n",
       " 'a copper statue of Christ',\n",
       " 188,\n",
       " 213)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = index_answer(train_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vocab = set()\n",
    "with open('glove/glove.840B.300d.txt') as f:\n",
    "    for line in f:\n",
    "        token = normalize_text(line.rstrip().split(' ')[0])\n",
    "        wv_vocab.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2195960"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(questions, contexts):\n",
    "    \"\"\"\n",
    "    Build vocabulary sorted by global word frequency, or consider frequencies in questions first,\n",
    "    which is controlled by `args.sort_all`.\n",
    "    \"\"\"\n",
    "    if True:\n",
    "        counter = collections.Counter(w for doc in questions + contexts for w in doc)\n",
    "        vocab = sorted([t for t in counter if t in wv_vocab], key=counter.get, reverse=True)\n",
    "    else:\n",
    "        counter_q = collections.Counter(w for doc in questions for w in doc)\n",
    "        counter_c = collections.Counter(w for doc in contexts for w in doc)\n",
    "        counter = counter_c + counter_q\n",
    "        vocab = sorted([t for t in counter_q if t in wv_vocab], key=counter_q.get, reverse=True)\n",
    "        vocab += sorted([t for t in counter_c.keys() - counter_q.keys() if t in wv_vocab],\n",
    "                        key=counter.get, reverse=True)\n",
    "    total = sum(counter.values())\n",
    "    matched = sum(counter[t] for t in vocab)\n",
    "    vocab.insert(0, \"<PAD>\") # in question_id and context_id, the 0 means padding\n",
    "    vocab.insert(1, \"<UNK>\")\n",
    "    return vocab, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter(w for doc in [row[5]] + [row[1]] for w in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = sorted([t for t in counter if t in wv_vocab], key=counter.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = sum(counter.values())\n",
    "matched = sum(counter[t] for t in vocab)\n",
    "matched == total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = train\n",
    "full = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, counter = build_vocab([row[5]], [row[1]])\n",
    "counter_tag = collections.Counter(w for w in row[3]) #context_tags\n",
    "vocab_tag = sorted(counter_tag, key=counter_tag.get, reverse=True) # high rank with larger count\n",
    "counter_ent = collections.Counter(w for w in row[4])\n",
    "vocab_ent = sorted(counter_ent, key=counter_ent.get, reverse=True)\n",
    "w2id = {w: i for i, w in enumerate(vocab)}\n",
    "tag2id = {w: i for i, w in enumerate(vocab_tag)} # larger count(hight rank) with small index\n",
    "ent2id = {w: i for i, w in enumerate(vocab_ent)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_id(row, unk_id=1):\n",
    "    context_tokens = row[1]\n",
    "    context_features = row[2]\n",
    "    context_tags = row[3]\n",
    "    context_ents = row[4]\n",
    "    question_tokens = row[5]\n",
    "    question_ids = [w2id[w] if w in w2id else unk_id for w in question_tokens]\n",
    "    context_ids = [w2id[w] if w in w2id else unk_id for w in context_tokens]\n",
    "    tag_ids = [tag2id[w] for w in context_tags]\n",
    "    ent_ids = [ent2id[w] for w in context_ents]\n",
    "    return (row[0], context_ids, context_features, tag_ids, ent_ids, question_ids) + row[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann_id = to_id(train, unk_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embeddings = np.zeros((vocab_size, 300))\n",
    "embed_counts = np.zeros(vocab_size)\n",
    "embed_counts[:2] = 1  # PADDING & UNK\n",
    "wv_file = 'glove/glove.840B.300d.txt'\n",
    "with open(wv_file) as f:\n",
    "    for line in f:\n",
    "        elems = line.rstrip().split(' ')\n",
    "        token = normalize_text(elems[0])\n",
    "        if token in w2id:\n",
    "            word_id = w2id[token]\n",
    "            embed_counts[word_id] += 1\n",
    "            embeddings[word_id] += [float(v) for v in elems[1:]]\n",
    "embeddings /= embed_counts.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings))\n",
    "print(len(embeddings[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add char embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngrams(sentence, n):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        list: a list of lists of words corresponding to the ngrams in the sentence.\n",
    "    \"\"\"\n",
    "    return [sentence[i:i+n] for i in range(len(sentence)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.embedding import Embedding\n",
    "class CharEmbedding(Embedding):\n",
    "\n",
    "    size = 874474\n",
    "    d_emb = 100\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.db = self.initialize_db(self.path('char/kazuma.db'))\n",
    "        if len(self) < self.size:\n",
    "            self.clear()\n",
    "            self.load_word2emb()\n",
    "            \n",
    "\n",
    "    def emb(self, w, default='zero'):\n",
    "        assert default == 'zero', 'only zero default is supported for character embeddings'\n",
    "        chars = ['#BEGIN#'] + list(w) + ['#END#']\n",
    "        embs = np.zeros(self.d_emb, dtype=np.float32)\n",
    "        match = {}\n",
    "        for i in [2, 3, 4]:\n",
    "            grams = ngrams(chars, i)\n",
    "            for g in grams:\n",
    "                g = '{}gram-{}'.format(i, ''.join(g))\n",
    "                e = self.lookup(g)\n",
    "                if e is not None:\n",
    "                    match[g] = np.array(e, np.float32)\n",
    "        if match:\n",
    "            embs = sum(match.values()) / len(match)\n",
    "        return embs.tolist()\n",
    "\n",
    "    def load_word2emb(self, batch_size=1000):\n",
    "        seen = set()\n",
    "        fin_name = 'char/charNgram.txt'\n",
    "        with open(fin_name, 'r') as ftxt:\n",
    "            content = ftxt.read()\n",
    "            lines = content.splitlines()\n",
    "            batch = []\n",
    "            for line in lines:\n",
    "                elems = line.rstrip().split()\n",
    "                vec = [float(n) for n in elems[-d_emb:]]\n",
    "                word = ' '.join(elems[:-d_emb])\n",
    "                if word in seen:\n",
    "                    continue\n",
    "                seen.add(word)                \n",
    "                batch.append((word, vec))\n",
    "                if len(batch) == batch_size:\n",
    "                    self.insert_batch(batch)\n",
    "                    batch.clear()\n",
    "            if batch:\n",
    "                self.insert_batch(batch)\n",
    "charembedding = CharEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "char_embeddings = np.zeros((vocab_size, 100))\n",
    "char_embed_counts = np.zeros(vocab_size)\n",
    "char_embed_counts[:2] = 1  # PADDING & UNK\n",
    "for token in w2id:\n",
    "    word_id = w2id[token]\n",
    "    char_embed_counts[word_id] += 1\n",
    "    char_embeddings[word_id] += charembedding.emb(token) \n",
    "char_embeddings /= char_embed_counts.reshape((-1, 1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_char_embedding = np.concatenate((embeddings, char_embeddings), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_char_embedding[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = glove_char_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 5, 6],\n",
       "       [3, 4, 1, 1, 2]])"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 1], [3, 4, 1]])\n",
    "b = np.array([[5, 6], [1,2]])\n",
    "np.concatenate((a, b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
