{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for DRQA data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import spacy\n",
    "import msgpack\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import argparse\n",
    "import collections\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import tqdm\n",
    "def clean_spaces(text):\n",
    "    \"\"\"normalize spaces in a string.\"\"\"\n",
    "    text = re.sub(r'\\s', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iob_np_tag(tag_list):\n",
    "    '''\n",
    "    @in: a list of POS tags\n",
    "    @out: iob_np tags\n",
    "    '''\n",
    "    iob_np = ['o_np'] * len(tag_list)\n",
    "    for i in range(len(tag_list)):\n",
    "        if 'NN' in tag_list[i]:\n",
    "            if iob_np[i-1] == 'b_np':\n",
    "                iob_np[i] = 'i_np'\n",
    "            elif iob_np[i-1] == 'i_np':\n",
    "                iob_np[i] = 'i_np'\n",
    "            else:\n",
    "                iob_np[i] = 'b_np'       \n",
    "        i +=1\n",
    "    return iob_np\n",
    "\n",
    "def iob_ner_tag(tag_list):\n",
    "    '''\n",
    "    @in: a list of ner tags\n",
    "    @out: iob_ner tags\n",
    "    '''\n",
    "    iob_ner = ['o_ner'] * len(tag_list)\n",
    "    for i in range(len(tag_list)):\n",
    "        if len(tag_list[i]) != 0:\n",
    "            if iob_ner[i-1] == 'b_ner':\n",
    "                iob_ner[i] = 'i_ner'\n",
    "            elif iob_ner[i-1] == 'i_ner':\n",
    "                iob_ner[i] = 'i_ner'\n",
    "            else:\n",
    "                iob_ner[i] = 'b_ner'       \n",
    "        i +=1\n",
    "    return iob_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    return unicodedata.normalize('NFD', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global nlp\n",
    "nlp = spacy.load('en', parser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JJ', 'JJ', 'NN', 'IN', 'NNP']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_doc = nlp('military academic institution in Poland')\n",
    "[w.tag_ for w in c_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNP',\n",
       " 'NNP',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'CD',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_doc = nlp('Microsoft Corporation is a technology company founded in 1975. This corporation develops computer software.')\n",
    "[w.tag_ for w in c_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORG', 'ORG', '', '', '', '', '', '', 'DATE', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.ent_type_ for w in c_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import unicodedata\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize('NFD', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the building has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'Architecturally, the building has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question = 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "q_doc = nlp(clean_spaces(question))\n",
    "c_doc = nlp(clean_spaces(context))\n",
    "question_tokens = [normalize_text(w.text) for w in q_doc]\n",
    "context_tokens = [normalize_text(w.text) for w in c_doc]\n",
    "question_tokens_lower = [w.lower() for w in question_tokens]\n",
    "context_tokens_lower = [w.lower() for w in context_tokens]\n",
    "context_token_span = [(w.idx, w.idx + len(w.text)) for w in c_doc] # the lenghth of each tokens\n",
    "context_tags = [w.tag_ for w in c_doc] # POS tagging\n",
    "context_ents = [w.ent_type_ for w in c_doc] # NER tagging\n",
    "context_iob_np = iob_np_tag(context_tags)\n",
    "context_iob_ner = iob_ner_tag(context_ents)\n",
    "\n",
    "question_lemma = {w.lemma_ if w.lemma_ != '-PRON-' else w.text.lower() for w in q_doc}\n",
    "# PRON is such as me/it/you\n",
    "# lemma_ : cats -> cat\n",
    "\n",
    "question_tokens_set = set(question_tokens)\n",
    "question_tokens_lower_set = set(question_tokens_lower)\n",
    "match_origin = [w in question_tokens_set for w in context_tokens]\n",
    "match_lower = [w in question_tokens_lower_set for w in context_tokens_lower]\n",
    "match_lemma = [(w.lemma_ if w.lemma_ != '-PRON-' else w.text.lower()) in question_lemma for w in c_doc]\n",
    "# term frequency in document\n",
    "counter_ = collections.Counter(context_tokens_lower)\n",
    "total = len(context_tokens_lower)\n",
    "context_tf = [counter_[w] / total for w in context_tokens_lower]\n",
    "context_features = list(zip(match_origin, match_lower, match_lemma, context_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catholic Main Building Main Building Christ Venite Ad Me Omnes Main Building Basilica Sacred Heart Grotto Marian Lourdes France Mary Saint Bernadette Soubirous 1858 end main drive 3 Dome Mary"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ner_context_lemma + ner_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['a', 'an', 'the', 'of', 'for', '\\'s', ]\n",
    "def part_ner_tag(tag_list, context_list):\n",
    "    '''\n",
    "    @in: a list of ner tags\n",
    "    @out: part of ner tags\n",
    "    '''\n",
    "    ner_context = []\n",
    "    part_ner = ['o_ner'] * len(tag_list)\n",
    "    for i in range(len(tag_list)):\n",
    "        if len(tag_list[i]) != 0 and context_list[i] not in stop_words:\n",
    "            part_ner[i] = 'i_ner'\n",
    "            ner_context.append(context_list[i])\n",
    "    \n",
    "    # combine lemma to ner_context list\n",
    "    ner_context_str = ' '.join(ner_context)\n",
    "    ner_context_ = nlp(ner_context_str)\n",
    "    ner_context_lemma = [w.lemma_ if w.lemma_ != '-PRON-' else w.text.lower() for w in ner_context_]\n",
    "    ner_context_all = ner_context_lemma +  ner_context\n",
    "        \n",
    "    for j in range(len(context_list)):\n",
    "        if context_list[j] in ner_context_all:\n",
    "            part_ner[j] = 'i_ner'\n",
    "    return part_ner, ner_context_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_ner ,ner_context_all= part_ner_tag(context_ents, context_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#df = pd.DataFrame(np.column_stack([context_ents, context_tokens, part_ner]))\n",
    "#print (df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(context_ents, context_iob_ner)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_answer(row):\n",
    "    token_span = row[-4]\n",
    "    starts, ends = zip(*token_span)\n",
    "    answer_start = row[-2]\n",
    "    answer_end = row[-1]\n",
    "    try:\n",
    "        return row[:-3] + (starts.index(answer_start), ends.index(answer_end))\n",
    "    except ValueError:\n",
    "        return row[:-3] + (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_span = context_token_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starts, ends = zip(*token_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = 'Saint Bernadette Soubirous'\n",
    "answer_start = 515\n",
    "answer_end = answer_start + len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts.index(answer_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ends.index(answer_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pos tagging count for context\n",
    "counter_tag = collections.Counter(w for w in context_tags) #context_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({\"''\": 1,\n",
       "         ',': 6,\n",
       "         '-LRB-': 1,\n",
       "         '-RRB-': 1,\n",
       "         '.': 7,\n",
       "         'CC': 4,\n",
       "         'CD': 2,\n",
       "         'DT': 22,\n",
       "         'IN': 20,\n",
       "         'JJ': 7,\n",
       "         'NN': 20,\n",
       "         'NNP': 27,\n",
       "         'NNS': 2,\n",
       "         'POS': 1,\n",
       "         'PRP': 3,\n",
       "         'RB': 5,\n",
       "         'VBD': 1,\n",
       "         'VBG': 1,\n",
       "         'VBZ': 8,\n",
       "         'WDT': 1,\n",
       "         'WRB': 1,\n",
       "         '``': 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_tag = sorted(counter_tag, key=counter_tag.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag2id = {w: i for i, w in enumerate(vocab_tag)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"''\": 16,\n",
       " ',': 7,\n",
       " '-LRB-': 19,\n",
       " '-RRB-': 21,\n",
       " '.': 6,\n",
       " 'CC': 9,\n",
       " 'CD': 12,\n",
       " 'DT': 1,\n",
       " 'IN': 3,\n",
       " 'JJ': 5,\n",
       " 'NN': 2,\n",
       " 'NNP': 0,\n",
       " 'NNS': 11,\n",
       " 'POS': 13,\n",
       " 'PRP': 10,\n",
       " 'RB': 8,\n",
       " 'VBD': 18,\n",
       " 'VBG': 14,\n",
       " 'VBZ': 4,\n",
       " 'WDT': 20,\n",
       " 'WRB': 17,\n",
       " '``': 15}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# largest count with small index number\n",
    "tag2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import msgpack\n",
    "with open('SQuAD/meta.msgpack', 'rb') as f:\n",
    "    meta = msgpack.load(f, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "embedding = torch.Tensor(meta['char_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([87603, 100])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o_ner', 'i_ner']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['vocab_part_ner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of pos tag given by spacy \n",
    "len(meta['vocab_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of NER tag given by spacy\n",
    "len(meta['vocab_ent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pos tag\n",
    "#meta['vocab_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#meta['vocab_ent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context\n",
    "data['train'][0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example cotext id \n",
    "#data['train'][0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for example pos tag_id\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data['train'][0][3], data['train'][0][5])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['vocab'][53946]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RB'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['vocab_tag'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta['embedding'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(meta['vocab']) == len(meta['char_embeddings']) ==91187"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 874474\n",
    "d_emb = 100\n",
    "seen = set()\n",
    "fin_name = 'char/charNgram.txt'\n",
    "with open(fin_name, 'r') as ftxt:\n",
    "    content = ftxt.read()\n",
    "    lines = content.splitlines()\n",
    "    batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    elems = line.rstrip().split()\n",
    "    vec = [float(n) for n in elems[-d_emb:]]\n",
    "    word = ' '.join(elems[:-d_emb])\n",
    "    if word in seen:\n",
    "        continue\n",
    "    seen.add(word)\n",
    "    batch.append((word, vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngrams(sentence, n):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        list: a list of lists of words corresponding to the ngrams in the sentence.\n",
    "    \"\"\"\n",
    "    return [sentence[i:i+n] for i in range(len(sentence)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emb(w, default='zero'):\n",
    "    assert default == 'zero', 'only zero default is supported for character embeddings'\n",
    "    chars = ['#BEGIN#'] + list(w) + ['#END#']\n",
    "    embs = np.zeros(d_emb, dtype=np.float32)\n",
    "    match = {}\n",
    "    for i in [2, 3, 4]:\n",
    "        grams = ngrams(chars, i)\n",
    "        for g in grams:\n",
    "            g = '{}gram-{}'.format(i, ''.join(g))\n",
    "            e = self.lookup(g)\n",
    "            if e is not None:\n",
    "                match[g] = np.array(e, np.float32)\n",
    "    if match:\n",
    "        embs = sum(match.values()) / len(match)\n",
    "    return embs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = ['#BEGIN#'] + list('cat') + ['#END#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embs = np.zeros(d_emb, dtype=np.float32)\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match = {}\n",
    "for i in [2, 3, 4]:\n",
    "    grams = ngrams(chars, i)\n",
    "    for g in grams:\n",
    "        g = '{}gram-{}'.format(i, ''.join(g))\n",
    "        print(g)\n",
    "        #e = lookup(g)\n",
    "        #if e is not None:\n",
    "        #    match[g] = np.array(e, np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepro.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_file = 'SQuAD/train-v1.1.json'\n",
    "import json\n",
    "\n",
    "def flatten_json(data_file, mode):\n",
    "    \"\"\"Flatten each article in training data.\"\"\"\n",
    "    with open(data_file) as f:\n",
    "        data = json.load(f)['data']\n",
    "    rows = []\n",
    "    for article in data:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                id_, question, answers = qa['id'], qa['question'], qa['answers']\n",
    "                if mode == 'train':\n",
    "                    answer = answers[0]['text']  # in training data there's only one answer\n",
    "                    answer_start = answers[0]['answer_start'] # char level length\n",
    "                    answer_end = answer_start + len(answer) # char level lenght\n",
    "                    rows.append((id_, context, question, answer, answer_start, answer_end))\n",
    "                else:  # mode == 'dev'\n",
    "                    answers = [a['text'] for a in answers]\n",
    "                    rows.append((id_, context, question, answers))\n",
    "    return rows\n",
    "\n",
    "\n",
    "train = flatten_json(trn_file, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5733bf84d058e614000b61bd',\n",
       " \"As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.\",\n",
       " 'How many student news papers are found at Notre Dame?',\n",
       " 'three',\n",
       " 126,\n",
       " 131)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vocab = set()\n",
    "with open('glove/glove.840B.300d.txt') as f:\n",
    "    for line in f:\n",
    "        token = normalize_text(line.rstrip().split(' ')[0])\n",
    "        wv_vocab.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2195960"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(questions, contexts):\n",
    "    \"\"\"\n",
    "    Build vocabulary sorted by global word frequency, or consider frequencies in questions first,\n",
    "    which is controlled by `args.sort_all`.\n",
    "    \"\"\"\n",
    "    if True:\n",
    "        counter = collections.Counter(w for doc in questions + contexts for w in doc)\n",
    "        vocab = sorted([t for t in counter if t in wv_vocab], key=counter.get, reverse=True)\n",
    "    else:\n",
    "        counter_q = collections.Counter(w for doc in questions for w in doc)\n",
    "        counter_c = collections.Counter(w for doc in contexts for w in doc)\n",
    "        counter = counter_c + counter_q\n",
    "        vocab = sorted([t for t in counter_q if t in wv_vocab], key=counter_q.get, reverse=True)\n",
    "        vocab += sorted([t for t in counter_c.keys() - counter_q.keys() if t in wv_vocab],\n",
    "                        key=counter.get, reverse=True)\n",
    "    total = sum(counter.values())\n",
    "    matched = sum(counter[t] for t in vocab)\n",
    "    vocab.insert(0, \"<PAD>\") # in question_id and context_id, the 0 means padding\n",
    "    vocab.insert(1, \"<UNK>\")\n",
    "    return vocab, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = collections.Counter(w for doc in [row[5]] + [row[1]] for w in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = sorted([t for t in counter if t in wv_vocab], key=counter.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = sum(counter.values())\n",
    "matched = sum(counter[t] for t in vocab)\n",
    "matched == total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = train\n",
    "full = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab, counter = build_vocab([row[5]], [row[1]])\n",
    "counter_tag = collections.Counter(w for w in row[3]) #context_tags\n",
    "vocab_tag = sorted(counter_tag, key=counter_tag.get, reverse=True) # high rank with larger count\n",
    "counter_ent = collections.Counter(w for w in row[4])\n",
    "vocab_ent = sorted(counter_ent, key=counter_ent.get, reverse=True)\n",
    "w2id = {w: i for i, w in enumerate(vocab)}\n",
    "tag2id = {w: i for i, w in enumerate(vocab_tag)} # larger count(hight rank) with small index\n",
    "ent2id = {w: i for i, w in enumerate(vocab_ent)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_id(row, unk_id=1):\n",
    "    context_tokens = row[1]\n",
    "    context_features = row[2]\n",
    "    context_tags = row[3]\n",
    "    context_ents = row[4]\n",
    "    question_tokens = row[5]\n",
    "    question_ids = [w2id[w] if w in w2id else unk_id for w in question_tokens]\n",
    "    context_ids = [w2id[w] if w in w2id else unk_id for w in context_tokens]\n",
    "    tag_ids = [tag2id[w] for w in context_tags]\n",
    "    ent_ids = [ent2id[w] for w in context_ents]\n",
    "    return (row[0], context_ids, context_features, tag_ids, ent_ids, question_ids) + row[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ann_id = to_id(train, unk_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embeddings = np.zeros((vocab_size, 300))\n",
    "embed_counts = np.zeros(vocab_size)\n",
    "embed_counts[:2] = 1  # PADDING & UNK\n",
    "wv_file = 'glove/glove.840B.300d.txt'\n",
    "with open(wv_file) as f:\n",
    "    for line in f:\n",
    "        elems = line.rstrip().split(' ')\n",
    "        token = normalize_text(elems[0])\n",
    "        if token in w2id:\n",
    "            word_id = w2id[token]\n",
    "            embed_counts[word_id] += 1\n",
    "            embeddings[word_id] += [float(v) for v in elems[1:]]\n",
    "embeddings /= embed_counts.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings))\n",
    "print(len(embeddings[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add char embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngrams(sentence, n):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        list: a list of lists of words corresponding to the ngrams in the sentence.\n",
    "    \"\"\"\n",
    "    return [sentence[i:i+n] for i in range(len(sentence)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from embeddings.embedding import Embedding\n",
    "class CharEmbedding(Embedding):\n",
    "\n",
    "    size = 874474\n",
    "    d_emb = 100\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.db = self.initialize_db(self.path('char/kazuma.db'))\n",
    "        if len(self) < self.size:\n",
    "            self.clear()\n",
    "            self.load_word2emb()\n",
    "            \n",
    "\n",
    "    def emb(self, w, default='zero'):\n",
    "        assert default == 'zero', 'only zero default is supported for character embeddings'\n",
    "        chars = ['#BEGIN#'] + list(w) + ['#END#']\n",
    "        embs = np.zeros(self.d_emb, dtype=np.float32)\n",
    "        match = {}\n",
    "        for i in [2, 3, 4]:\n",
    "            grams = ngrams(chars, i)\n",
    "            for g in grams:\n",
    "                g = '{}gram-{}'.format(i, ''.join(g))\n",
    "                e = self.lookup(g)\n",
    "                if e is not None:\n",
    "                    match[g] = np.array(e, np.float32)\n",
    "        if match:\n",
    "            embs = sum(match.values()) / len(match)\n",
    "        return embs.tolist()\n",
    "\n",
    "    def load_word2emb(self, batch_size=1000):\n",
    "        seen = set()\n",
    "        fin_name = 'char/charNgram.txt'\n",
    "        with open(fin_name, 'r') as ftxt:\n",
    "            content = ftxt.read()\n",
    "            lines = content.splitlines()\n",
    "            batch = []\n",
    "            for line in lines:\n",
    "                elems = line.rstrip().split()\n",
    "                vec = [float(n) for n in elems[-d_emb:]]\n",
    "                word = ' '.join(elems[:-d_emb])\n",
    "                if word in seen:\n",
    "                    continue\n",
    "                seen.add(word)                \n",
    "                batch.append((word, vec))\n",
    "                if len(batch) == batch_size:\n",
    "                    self.insert_batch(batch)\n",
    "                    batch.clear()\n",
    "            if batch:\n",
    "                self.insert_batch(batch)\n",
    "charembedding = CharEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "char_embeddings = np.zeros((vocab_size, 100))\n",
    "char_embed_counts = np.zeros(vocab_size)\n",
    "char_embed_counts[:2] = 1  # PADDING & UNK\n",
    "for token in w2id:\n",
    "    word_id = w2id[token]\n",
    "    char_embed_counts[word_id] += 1\n",
    "    char_embeddings[word_id] += charembedding.emb(token) \n",
    "char_embeddings /= char_embed_counts.reshape((-1, 1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_char_embedding = np.concatenate((embeddings, char_embeddings), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_char_embedding[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = glove_char_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 5, 6],\n",
       "       [3, 4, 1, 1, 2]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 1], [3, 4, 1]])\n",
    "b = np.array([[5, 6], [1,2]])\n",
    "np.concatenate((a, b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1],\n",
       "       [3, 4, 1]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test new added feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spaces(text):\n",
    "    \"\"\"normalize spaces in a string.\"\"\"\n",
    "    text = re.sub(r'\\s', ' ', text)\n",
    "    return text\n",
    "\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize('NFD', text)\n",
    "\n",
    "nlp = None\n",
    "\n",
    "def init():\n",
    "    \"\"\"initialize spacy in each process\"\"\"\n",
    "    '''\n",
    "    'en': Noun chunks are \"base noun phrases\" â€“ flat phrases that have a noun as their head.\n",
    "    parser=False or disable=['parser'] : don't need any of the syntactic information,\n",
    "                                        and will make spaCy load and run much faster.\n",
    "    '''\n",
    "    global nlp\n",
    "    nlp = spacy.load('en', parser=False)\n",
    "\n",
    "def annotate(row):\n",
    "    global nlp\n",
    "    id_, context, question = row[:3]\n",
    "    q_doc = nlp(clean_spaces(question))\n",
    "    c_doc = nlp(clean_spaces(context))\n",
    "    question_tokens = [normalize_text(w.text) for w in q_doc]\n",
    "    context_tokens = [normalize_text(w.text) for w in c_doc]\n",
    "    question_tokens_lower = [w.lower() for w in question_tokens]\n",
    "    context_tokens_lower = [w.lower() for w in context_tokens]\n",
    "    context_token_span = [(w.idx, w.idx + len(w.text)) for w in c_doc] # the lenghth of each tokens\n",
    "    context_tags = [w.tag_ for w in c_doc] # POS tagging\n",
    "    context_ents = [w.ent_type_ for w in c_doc] # NER tagging\n",
    "\n",
    "    question_lemma = {w.lemma_ if w.lemma_ != '-PRON-' else w.text.lower() for w in q_doc}\n",
    "    # PRON is such as me/it/you\n",
    "    # lemma_ : cats -> cat\n",
    "\n",
    "    question_tokens_set = set(question_tokens)\n",
    "    question_tokens_lower_set = set(question_tokens_lower)\n",
    "    match_origin = [w in question_tokens_set for w in context_tokens]\n",
    "    match_lower = [w in question_tokens_lower_set for w in context_tokens_lower]\n",
    "    match_lemma = [(w.lemma_ if w.lemma_ != '-PRON-' else w.text.lower()) in question_lemma for w in c_doc]\n",
    "    # term frequency in document\n",
    "    counter_ = collections.Counter(context_tokens_lower)\n",
    "    total = len(context_tokens_lower)\n",
    "    # frequent feature\n",
    "    context_tf = [counter_[w] / total for w in context_tokens_lower]\n",
    "    # exact match feature refering to the paper\n",
    "    context_features = list(zip(match_origin, match_lower, match_lemma, context_tf))\n",
    "    if not True:\n",
    "        context_tokens = context_tokens_lower\n",
    "        question_tokens = question_tokens_lower\n",
    "    return (id_, context_tokens, context_features, context_tags, context_ents,\n",
    "            question_tokens, context, context_token_span) + row[3:]\n",
    "def index_answer(row):\n",
    "    token_span = row[-4] #context_token_span\n",
    "    starts, ends = zip(*token_span)\n",
    "    answer_start = row[-2]\n",
    "    answer_end = row[-1]\n",
    "    try:\n",
    "        return row[:-3] + (starts.index(answer_start), ends.index(answer_end))\n",
    "    except ValueError:\n",
    "        return row[:-3] + (None, None)\n",
    "nlp = spacy.load('en', parser=False)\n",
    "train_ann = annotate(train[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How',\n",
       " 'many',\n",
       " 'student',\n",
       " 'news',\n",
       " 'papers',\n",
       " 'are',\n",
       " 'found',\n",
       " 'at',\n",
       " 'Notre',\n",
       " 'Dame',\n",
       " '?']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ann[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SQuAD/data.msgpack', 'rb') as f:\n",
    "    data = msgpack.load(f, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train: id, context_id, context_features, tag_id, ent_id, iob_np, iob_ner, part_ner, \n",
    "#        q tag_id, q ent_id, q iob_np, q iob_ner,\n",
    "#        question_id, context, context_token_span, answer_start, answer_end\n",
    "#data['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#df = pd.DataFrame(np.column_stack([data['train'][8][4],data['train'][8][3]]))\n",
    "#print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0  1  2  3        4\n",
      "0   12  0  0  0      How\n",
      "1    5  0  0  0     many\n",
      "2    0  0  1  0  student\n",
      "3    0  0  2  0     news\n",
      "4    8  0  2  0   papers\n",
      "5   13  0  0  0      are\n",
      "6   10  0  0  0    found\n",
      "7    1  0  0  0       at\n",
      "8    2  2  1  1    Notre\n",
      "9    2  2  2  2     Dame\n",
      "10   3  0  0  0        ?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(np.column_stack([data['train'][8][8],data['train'][8][9], data['train'][8][10],data['train'][8][11],train_ann[5]]))\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SQuAD/meta.msgpack', 'rb') as f:\n",
    "    meta = msgpack.load(f, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta['vocab_q_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vocab', 'vocab_tag', 'vocab_ent', 'embedding', 'char_embedding', 'glove_char_embedding', 'vocab_iob_np', 'vocab_iob_ner', 'vocab_part_ner', 'vocab_q_tag', 'vocab_q_ent', 'vocab_q_iob_np', 'vocab_q_iob_ner'])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Sean/Desktop/ds1012_final_project'"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vocab', 'vocab_tag', 'vocab_ent', 'embedding', 'char_embedding', 'glove_char_embedding', 'vocab_iob_np', 'vocab_iob_ner', 'vocab_part_ner', 'vocab_q_tag', 'vocab_q_ent', 'vocab_q_iob_np', 'vocab_q_iob_ner'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'dev'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev:   id, context_id, context_features, tag_id, ent_id, iob_np_ids, iob_ner_ids, part_ner_ids,\n",
    "#        question_id, context, context_token_span, answer\n",
    "context = data['dev'][0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the id match \n",
    "dev[0][0] == data['dev'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map id back to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'part_ner_tag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-61d8bdefe560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_ann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-fd9fdd05fc51>\u001b[0m in \u001b[0;36mannotate\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mcontext_iob_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miob_np_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_tags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# iob_np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mcontext_iob_ner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miob_ner_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_ents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#iob_ner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mcontext_part_ner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart_ner_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_ents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_tokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#part_ner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m#for question the new features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'part_ner_tag' is not defined"
     ]
    }
   ],
   "source": [
    "dev_ann = annotate(dev[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Denver Broncos', 'Denver Broncos', 'Denver Broncos']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_ann = dev_ann[-1]\n",
    "answer_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24â€“10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contex_ann = dev_ann[-3]\n",
    "contex_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(np.column_stack([data['dev'][0][8],data['dev'][0][9], data['dev'][0][10],data['dev'][0][11],dev_ann[5]]))\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-81-6f8e0292ea74>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-81-6f8e0292ea74>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    dev_ann[]\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dev_ann[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(4,4)\n",
    "ee = torch.randn(4,6)\n",
    "b = torch.randn(4,5)\n",
    "c = torch.randn(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [a,ee]\n",
    "list_.append(b)\n",
    "list_.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " -1.2702 -1.8569  0.4600  0.1064\n",
       "  0.4058  0.1211 -1.3250  0.2720\n",
       "  0.2532  1.7568 -0.8371  0.2591\n",
       " -0.4002  1.0083 -0.9354 -0.4041\n",
       " [torch.FloatTensor of size 4x4], \n",
       " -0.9446 -0.4591  1.5962  1.0960 -0.4257  0.3042\n",
       " -0.7830 -0.7529  0.6747  0.9685 -1.6344 -0.3820\n",
       " -0.5750 -0.3853 -1.4120  2.1387  0.3732  0.9374\n",
       " -2.4007  1.2158 -0.8062 -0.1280 -0.6776 -0.5533\n",
       " [torch.FloatTensor of size 4x6], \n",
       " -0.1084  1.8311 -1.9461 -0.3505 -0.5678\n",
       " -0.3808 -1.8617  1.3735  0.9692  0.3530\n",
       "  0.2152 -0.6362  0.4172 -1.3567  1.0117\n",
       " -0.8054  0.6637  0.5527  0.5326 -1.5344\n",
       " [torch.FloatTensor of size 4x5], \n",
       " -0.9352 -0.1562\n",
       " -0.6677 -0.1769\n",
       "  0.5419 -1.4153\n",
       " -0.6163 -0.2632\n",
       " [torch.FloatTensor of size 4x2]]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "drnn_input = torch.cat(list_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 17])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drnn_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2_pos is torch.Size([4, 11])\n"
     ]
    }
   ],
   "source": [
    "print('x2_pos is {}'.format(drnn_input.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = [1,1,1,1,None, None,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [2*e for e in ex[0:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, None, None, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input+ ex[4:6] + [2*e for e in ex[-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, None, None, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty = torch.FloatTensor()\n",
    "len(empty) ==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       " -1.2702 -1.8569  0.4600  0.1064 -0.9446 -0.4591  1.5962  1.0960 -0.4257  0.3042\n",
       "  0.4058  0.1211 -1.3250  0.2720 -0.7830 -0.7529  0.6747  0.9685 -1.6344 -0.3820\n",
       "  0.2532  1.7568 -0.8371  0.2591 -0.5750 -0.3853 -1.4120  2.1387  0.3732  0.9374\n",
       " -0.4002  1.0083 -0.9354 -0.4041 -2.4007  1.2158 -0.8062 -0.1280 -0.6776 -0.5533\n",
       " \n",
       " Columns 10 to 16 \n",
       " -0.1084  1.8311 -1.9461 -0.3505 -0.5678 -0.9352 -0.1562\n",
       " -0.3808 -1.8617  1.3735  0.9692  0.3530 -0.6677 -0.1769\n",
       "  0.2152 -0.6362  0.4172 -1.3567  1.0117  0.5419 -1.4153\n",
       " -0.8054  0.6637  0.5527  0.5326 -1.5344 -0.6163 -0.2632\n",
       " [torch.FloatTensor of size 4x17],\n",
       " Variable containing:[torch.FloatTensor with no dimension],\n",
       " 2,\n",
       " 3,\n",
       " 4]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "[Variable(drnn_input)] + [Variable(empty)] + [2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
